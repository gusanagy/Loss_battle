{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import *\n",
    "import torch\n",
    "from models import *\n",
    "from src.dataload import *\n",
    "from tqdm.notebook import tqdm\n",
    "from metrics.metrics import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataloader UIEBUIEB\n",
    "train_loader_UIEB, test_loader_UIEB = create_dataloader(dataset_name=\"UIEB\", dataset_path=\"data\")\n",
    "\n",
    "#dataloader TURBID\n",
    "train_loader_TURBID, test_loader_TURBID = create_dataloader(dataset_name=\"TURBID\", dataset_path=\"data\")\n",
    "\n",
    "#dataloader LSUI\n",
    "train_loader_LSUI, test_loader_LSUI = create_dataloader(dataset_name=\"LSUI\", dataset_path=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 16]) torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.randn(1, 3, 256, 256).to(device)\n",
    "modelos = load_models()\n",
    "for model in modelos:\n",
    "    model = model.to(device)\n",
    "    if type(model(x)) is tuple:\n",
    "        print(model(x)[0].shape, model(x)[1].shape, model(x)[2].shape)\n",
    "    else:\n",
    "        print(model(x).shape)\n",
    "\n",
    "if type(model(x)) is tuple:\n",
    "        print(model(x)[0].shape, model(x)[1].shape, model(x)[2].shape)\n",
    "    else:\n",
    "        print(model(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema Atual\n",
    "### Notas sobre as Loss\n",
    "A loss lch nao esta funcionando. Ainda nao sei pq nao esta gerando resultado na loss.\n",
    "\n",
    "Serao reajustadas para o intervalo de zero a 1 : (Feito)\n",
    "* Histogram\n",
    "* darkchannel\n",
    "* hsv\n",
    "\n",
    "Falta fazer\n",
    "\n",
    "* lch nao funciona (Falta fazer)\n",
    "### Notas\n",
    "\n",
    "* Maiores problemas no autoencoder e em seu funcionamento. A dimensao latente de 16 nao gera nada aparentemente. \n",
    "* Talvez alterar o intervalo numero dos canais de cor ajude neste caso. O intervalo entre zero e 1 fazer 1/loss -1.\n",
    "    * As funcoes de perda caso seja colocadas entre o intervalo de 0 a 1 ainda se comportam gerando valores negativos. Talvez esta seja uma caracteristica desse tip de funcao e do tipo de dado que esta sendo passado. Talvez passando os dados entre -1 e 1 isso possa ser ajustado. Essa transformacao serveria apenas para as funcoes relacioandas a cor que parecem sofrer mais com este problema.\n",
    "* Terei de retreinar para passar os resultados\n",
    "* Para selecionar as melhores loss function devemos utilizar outro metodo. Nao sera possivel utilizar as metricas devido a grande quantidade de funcoes que nao gera imagem como a MSE e a SSIM. Essas funcoes tem de ser investigadas. \n",
    "* Como o tempo esta curso talvez seja melhor selecionar visualmente as melhores funcoes e agrupar de acordo com as necessidades do script.\n",
    "* Ainda preciso revisar os excperimentos do sbr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 loss functions to train with\n",
      "\n",
      "    HistogramColorLoss, result: -2.001150131225586     type<class 'torch.Tensor'>)\n",
      "    angular_color_loss, result: 0.9973129034042358     type<class 'torch.Tensor'>)\n",
      "    DarkChannelLoss, result: -2.004344940185547     type<class 'torch.Tensor'>)\n",
      "    LCHChannelLoss, result: nan     type<class 'torch.Tensor'>)\n",
      "    HSVChannelLoss, result: -1.0     type<class 'torch.Tensor'>)\n"
     ]
    }
   ],
   "source": [
    "#modelos = load_models()\n",
    "import torch\n",
    "from loss import *\n",
    "from models import *\n",
    "from src.dataload import *\n",
    "from tqdm.notebook import tqdm\n",
    "from metrics.metrics import *\n",
    "loss_battle = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#loss_battle.extend(build_perceptual_losses(rank=device))\n",
    "loss_battle.extend(build_channel_losses(rank = device))\n",
    "#loss_battle.extend(build_structural_losses(rank = device))\n",
    "\n",
    "print(f\"{len(loss_battle)} loss functions to train with\\n\")\n",
    "#print(f\"{len(modelos)} models to train with\")\n",
    "\n",
    "x = torch.randn(1, 3, 256, 256).to(device)\n",
    "y = torch.randn(1, 3, 256, 256).to(device)\n",
    "for loss_fn in loss_battle:\n",
    "    print(f\"    {loss_fn.name}, result: {loss_fn(x, y)}     type{type(loss_fn(x, x))})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0532e-07])\n",
      "tensor([1.0532e-07])\n",
      "tensor([-1.0000])\n",
      "tensor([-1.0000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalize_loss_output(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        \n",
    "        result  = (1/result)\n",
    "        print(result)\n",
    "\n",
    "        # Lidar com valores infinitos no tensor\n",
    "        result = torch.where(torch.isinf(result), torch.tensor(1.0), result)\n",
    "        result = torch.where(result == -float('inf'), torch.tensor(0.0), result)\n",
    "        print(result)\n",
    "        result = result -1\n",
    "        print(result)\n",
    "        \n",
    "        \n",
    "        # # Obter o valor mínimo e máximo do tensor\n",
    "        # min_val = torch.min(result)\n",
    "        # max_val = torch.max(result)\n",
    "        \n",
    "        # # Normalização para o intervalo [0, 1]\n",
    "        # if max_val > min_val:\n",
    "        #     normalized_result = (result - min_val) / (max_val - min_val)\n",
    "        # else:\n",
    "        #     normalized_result = torch.zeros_like(result)\n",
    "        \n",
    "        # # Garantir que o tensor esteja no intervalo [0, 1]\n",
    "        # normalized_result = torch.clamp(normalized_result, 0, 1)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "@normalize_loss_output\n",
    "def a():\n",
    "    #return torch.Tensor([np.inf])\n",
    "    return torch.Tensor([9494949])\n",
    "print(a())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outos ajustes ddp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader, DistributedSampler, TensorDataset\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "    print(f\"Rank {rank} initialized.\")\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "def train(rank, world_size, epochs=100):\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    #dataloader UIEBUIEB\n",
    "    train_loader_UIEB, test_loader_UIEB,sampler = create_dataloader(dataset_name=\"UIEB\", dataset_path=\"data\",world_size=world_size,rank=rank,rank_test=0)\n",
    "\n",
    "    model = model.cuda(rank)##carrega o modelo\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    criterion = nn.MSELoss().cuda(rank)##carrega loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ddp_model.train()\n",
    "        sampler.set_epoch(epoch)\n",
    "        for batch_idx, (data, target) in enumerate(train_loader_UIEB):\n",
    "            data, target = data.cuda(rank), target.cuda(rank)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = ddp_model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Rank {rank}, Epoch [{epoch}/{epochs}], Batch [{batch_idx}/{len(dataloader)}], Loss: {loss.item()}\")\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10, help=\"Number of epochs\")\n",
    "    parser.add_argument(\"--nodes\", type=int, default=1, help=\"Number of nodes\")\n",
    "    parser.add_argument(\"--gpus\", type=int, default=2, help=\"Number of GPUs per node\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    world_size = args.nodes * args.gpus\n",
    "\n",
    "    torch.multiprocessing.spawn(train, args=(world_size, args.epochs), nprocs=args.gpus, join=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%torchrun --nnodes=2 --nproc_per_node=2 --node_rank=0 --master_addr=\"10.228.252.209\" --master_port=12355 train_ddp.py --nodes=2 --gpus=2 --epochs=10\n",
    "#10.228.247.253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader, DistributedSampler, TensorDataset\n",
    "from loss import *\n",
    "import torch\n",
    "from models import *\n",
    "from src.dataload import *\n",
    "from tqdm.notebook import tqdm\n",
    "from metrics.metrics import *\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "    print(f\"Rank {rank} initialized.\")\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def train_one_model(rank, world_size, epochs, loss_fn, model_name, model):\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    #dataloader UIEBUIEB\n",
    "    train_loader_UIEB, test_loader_UIEB,sampler = create_dataloader(dataset_name=\"UIEB\", dataset_path=\"data\",world_size=world_size,rank=rank,rank_test=0)\n",
    "\n",
    "    modell = model.cuda(rank)\n",
    "    ddp_model = DDP(modell, device_ids=[rank])\n",
    "\n",
    "    criterion = loss_fn().cuda(rank)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ddp_model.train()\n",
    "        sampler.set_epoch(epoch)\n",
    "        for batch_idx, (data, target) in enumerate(train_loader_UIEB):\n",
    "            data, target = data.cuda(rank), target.cuda(rank)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = ddp_model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Rank {rank}, Epoch [{epoch}/{epochs}], Batch [{batch_idx}/{len(train_loader_UIEB)}], Loss: {loss.item()}\")\n",
    "    ##Salve Dir para salvar os checkpoints\n",
    "    ckpt_savedir='output/ckpt_battle/'\n",
    "    if not os.path.exists(ckpt_savedir):\n",
    "        os.makedirs(ckpt_savedir)\n",
    "    if rank == 0:\n",
    "        # Salvar o estado do modelo original, não o DDP\n",
    "        torch.save(model.state_dict(), f\"{ckpt_savedir}{model_name}_ckpt.pth\")\n",
    "        psnr_list, ssim_list, uciqe_list, uiqm_list = [], [], [], []\n",
    "        # Avaliar o modelo\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader_UIEB):\n",
    "                data, target = data.cuda(rank), target.cuda(rank)\n",
    "                #calcula a metrica\n",
    "                targets = target.cpu().numpy()\n",
    "                predictions = model(data.cuda(rank)).cpu().numpy()\n",
    "                psnr_value, ssim_value, uciqe_, uiqm = calculate_metrics(predictions, targets)\n",
    "                psnr_list.append(psnr_value)\n",
    "                ssim_list.append(ssim_value)\n",
    "                uciqe_list.append(uciqe_)\n",
    "                uiqm_list.append(uiqm)\n",
    "        avg_ssim = sum(ssim_list) / len(ssim_list)\n",
    "        avg_psnr = sum(psnr_list) / len(psnr_list)\n",
    "        avg_uciqe = sum(uciqe_list) / len(uciqe_list)\n",
    "        avg_uiqm = sum(uiqm_list) / len(uiqm_list)\n",
    "           \n",
    "        # Salvar métricas em um arquivo\n",
    "        results_savedir='output/results_battle/'\n",
    "        if not os.path.exists(results_savedir):\n",
    "            os.makedirs(results_savedir)\n",
    "        \n",
    "        with open(f'output/{model_name}_metrics.txt', 'w') as f:\n",
    "            f.write(f\"\"\"avg_ssim:{avg_ssim}\\navg_psnr:{avg_psnr}\\navg_uciqe:{avg_uciqe}\\navg_uiqm:{avg_uiqm}\"\"\")\n",
    "            print(f\"Metrics for {model_name} saved to {results_savedir}/{model_name}_metrics.txt\")\n",
    "\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "def train(rank, world_size, epochs):\n",
    "    \n",
    "    modelos = load_models()\n",
    "    loss_battle = []\n",
    "\n",
    "    loss_battle.extend(build_perceptual_losses())\n",
    "    loss_battle.extend(build_channel_losses())\n",
    "    loss_battle.extend(build_structural_losses())\n",
    "\n",
    "    for model in modelos:\n",
    "        for loss_fn in loss_battle:\n",
    "            model_name = model.__class__.__name__ + \"_\" + loss_fn.__class__.__name__\n",
    "            train_one_model(rank, world_size, epochs, loss_fn, model_name, model)        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100, help=\"Number of epochs per model\")\n",
    "    parser.add_argument(\"--nodes\", type=int, default=1, help=\"Number of nodes\")\n",
    "    parser.add_argument(\"--gpus\", type=int, default=2, help=\"Number of GPUs per node\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    world_size = args.nodes * args.gpus\n",
    "\n",
    "    torch.multiprocessing.spawn(train, args=(world_size, args.epochs), nprocs=args.gpus, join=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodar no cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchrun --nnodes=2 --nproc_per_node=2 --node_rank=0 --master_addr=\"10.228.252.209\" --master_port=22 main.py --nodes=2 --gpus=2 --epochs=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local\n",
    "torchrun --nproc_per_node=2 main.py --nodes=1 --gpus=2 --epochs=100\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "losstest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
