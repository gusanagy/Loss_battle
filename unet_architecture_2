digraph {
	graph [size="54.6,54.6"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	129890226784608 [label="
 (1, 3, 256, 256)" fillcolor=darkolivegreen1]
	129890245395456 [label=ConvolutionBackward0]
	129890245395696 -> 129890245395456
	129890245395696 [label=NativeBatchNormBackward0]
	129890245405920 -> 129890245395696
	129890245405920 [label=ReluBackward0]
	129890232122624 -> 129890245405920
	129890232122624 [label=ConvolutionBackward0]
	129890245403328 -> 129890232122624
	129890245403328 [label=NativeBatchNormBackward0]
	129890245401744 -> 129890245403328
	129890245401744 [label=ReluBackward0]
	129890245406736 -> 129890245401744
	129890245406736 [label=ConvolutionBackward0]
	129890245406976 -> 129890245406736
	129890245406976 [label=CatBackward0]
	129890245407552 -> 129890245406976
	129890245407552 [label=ConvolutionBackward0]
	129890245408800 -> 129890245407552
	129890245408800 [label=NativeBatchNormBackward0]
	129890245409664 -> 129890245408800
	129890245409664 [label=ReluBackward0]
	129890245410000 -> 129890245409664
	129890245410000 [label=ConvolutionBackward0]
	129890559670160 -> 129890245410000
	129890559670160 [label=NativeBatchNormBackward0]
	129890262141104 -> 129890559670160
	129890262141104 [label=ReluBackward0]
	129890246297920 -> 129890262141104
	129890246297920 [label=ConvolutionBackward0]
	129890246297680 -> 129890246297920
	129890246297680 [label=CatBackward0]
	129890119878400 -> 129890246297680
	129890119878400 [label=ConvolutionBackward0]
	129890560150592 -> 129890119878400
	129890560150592 [label=NativeBatchNormBackward0]
	129890232173664 -> 129890560150592
	129890232173664 [label=ReluBackward0]
	129890274247008 -> 129890232173664
	129890274247008 [label=ConvolutionBackward0]
	129890583577456 -> 129890274247008
	129890583577456 [label=NativeBatchNormBackward0]
	129890242011696 -> 129890583577456
	129890242011696 [label=ReluBackward0]
	129890242010784 -> 129890242011696
	129890242010784 [label=ConvolutionBackward0]
	129890242009824 -> 129890242010784
	129890242009824 [label=CatBackward0]
	129890242006896 -> 129890242009824
	129890242006896 [label=ConvolutionBackward0]
	129890242006416 -> 129890242006896
	129890242006416 [label=NativeBatchNormBackward0]
	129890242006224 -> 129890242006416
	129890242006224 [label=ReluBackward0]
	129890242006032 -> 129890242006224
	129890242006032 [label=ConvolutionBackward0]
	129890242005936 -> 129890242006032
	129890242005936 [label=NativeBatchNormBackward0]
	129890242005696 -> 129890242005936
	129890242005696 [label=ReluBackward0]
	129890242005504 -> 129890242005696
	129890242005504 [label=ConvolutionBackward0]
	129890242005408 -> 129890242005504
	129890242005408 [label=MaxPool2DWithIndicesBackward0]
	129890242006992 -> 129890242005408
	129890242006992 [label=NativeBatchNormBackward0]
	129890242004832 -> 129890242006992
	129890242004832 [label=ReluBackward0]
	129890242004592 -> 129890242004832
	129890242004592 [label=ConvolutionBackward0]
	129890242004496 -> 129890242004592
	129890242004496 [label=NativeBatchNormBackward0]
	129890242004304 -> 129890242004496
	129890242004304 [label=ReluBackward0]
	129890242004112 -> 129890242004304
	129890242004112 [label=ConvolutionBackward0]
	129890242003968 -> 129890242004112
	129890242003968 [label=MaxPool2DWithIndicesBackward0]
	129890119881664 -> 129890242003968
	129890119881664 [label=NativeBatchNormBackward0]
	129890242003584 -> 129890119881664
	129890242003584 [label=ReluBackward0]
	129890242003344 -> 129890242003584
	129890242003344 [label=ConvolutionBackward0]
	129890242003248 -> 129890242003344
	129890242003248 [label=NativeBatchNormBackward0]
	129890242003008 -> 129890242003248
	129890242003008 [label=ReluBackward0]
	129890231039696 -> 129890242003008
	129890231039696 [label=ConvolutionBackward0]
	129890231040752 -> 129890231039696
	129890231040752 [label=MaxPool2DWithIndicesBackward0]
	129890245405680 -> 129890231040752
	129890245405680 [label=NativeBatchNormBackward0]
	129890231036624 -> 129890245405680
	129890231036624 [label=ReluBackward0]
	129890231037632 -> 129890231036624
	129890231037632 [label=ConvolutionBackward0]
	129890231037824 -> 129890231037632
	129890231037824 [label=NativeBatchNormBackward0]
	129890231041472 -> 129890231037824
	129890231041472 [label=ReluBackward0]
	129890231039264 -> 129890231041472
	129890231039264 [label=ConvolutionBackward0]
	129890231036480 -> 129890231039264
	129890226786528 [label="encoder_layers.0.double_conv.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	129890226786528 -> 129890231036480
	129890231036480 [label=AccumulateGrad]
	129890231036576 -> 129890231039264
	129890226787248 [label="encoder_layers.0.double_conv.0.bias
 (64)" fillcolor=lightblue]
	129890226787248 -> 129890231036576
	129890231036576 [label=AccumulateGrad]
	129890231039744 -> 129890231037824
	129890226787168 [label="encoder_layers.0.double_conv.2.weight
 (64)" fillcolor=lightblue]
	129890226787168 -> 129890231039744
	129890231039744 [label=AccumulateGrad]
	129890231034992 -> 129890231037824
	129890226787328 [label="encoder_layers.0.double_conv.2.bias
 (64)" fillcolor=lightblue]
	129890226787328 -> 129890231034992
	129890231034992 [label=AccumulateGrad]
	129890231041952 -> 129890231037632
	129890226789808 [label="encoder_layers.0.double_conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	129890226789808 -> 129890231041952
	129890231041952 [label=AccumulateGrad]
	129890231037920 -> 129890231037632
	129890226790208 [label="encoder_layers.0.double_conv.3.bias
 (64)" fillcolor=lightblue]
	129890226790208 -> 129890231037920
	129890231037920 [label=AccumulateGrad]
	129890231040704 -> 129890245405680
	129890226790288 [label="encoder_layers.0.double_conv.5.weight
 (64)" fillcolor=lightblue]
	129890226790288 -> 129890231040704
	129890231040704 [label=AccumulateGrad]
	129890231038256 -> 129890245405680
	129890226789728 [label="encoder_layers.0.double_conv.5.bias
 (64)" fillcolor=lightblue]
	129890226789728 -> 129890231038256
	129890231038256 [label=AccumulateGrad]
	129890231040800 -> 129890231039696
	129890226793008 [label="encoder_layers.1.double_conv.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	129890226793008 -> 129890231040800
	129890231040800 [label=AccumulateGrad]
	129890231033984 -> 129890231039696
	129890226793088 [label="encoder_layers.1.double_conv.0.bias
 (128)" fillcolor=lightblue]
	129890226793088 -> 129890231033984
	129890231033984 [label=AccumulateGrad]
	129890242003056 -> 129890242003248
	129890226793568 [label="encoder_layers.1.double_conv.2.weight
 (128)" fillcolor=lightblue]
	129890226793568 -> 129890242003056
	129890242003056 [label=AccumulateGrad]
	129890242003104 -> 129890242003248
	129890226793488 [label="encoder_layers.1.double_conv.2.bias
 (128)" fillcolor=lightblue]
	129890226793488 -> 129890242003104
	129890242003104 [label=AccumulateGrad]
	129890242003296 -> 129890242003344
	129890226792688 [label="encoder_layers.1.double_conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	129890226792688 -> 129890242003296
	129890242003296 [label=AccumulateGrad]
	129890242003488 -> 129890242003344
	129890226791888 [label="encoder_layers.1.double_conv.3.bias
 (128)" fillcolor=lightblue]
	129890226791888 -> 129890242003488
	129890242003488 [label=AccumulateGrad]
	129890242003824 -> 129890119881664
	129890226792768 [label="encoder_layers.1.double_conv.5.weight
 (128)" fillcolor=lightblue]
	129890226792768 -> 129890242003824
	129890242003824 [label=AccumulateGrad]
	129890242003728 -> 129890119881664
	129890226792608 [label="encoder_layers.1.double_conv.5.bias
 (128)" fillcolor=lightblue]
	129890226792608 -> 129890242003728
	129890242003728 [label=AccumulateGrad]
	129890242004064 -> 129890242004112
	129890226794128 [label="encoder_layers.2.double_conv.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	129890226794128 -> 129890242004064
	129890242004064 [label=AccumulateGrad]
	129890242004208 -> 129890242004112
	129890226786688 [label="encoder_layers.2.double_conv.0.bias
 (256)" fillcolor=lightblue]
	129890226786688 -> 129890242004208
	129890242004208 [label=AccumulateGrad]
	129890242004352 -> 129890242004496
	129890226786608 [label="encoder_layers.2.double_conv.2.weight
 (256)" fillcolor=lightblue]
	129890226786608 -> 129890242004352
	129890242004352 [label=AccumulateGrad]
	129890242004400 -> 129890242004496
	129890226786928 [label="encoder_layers.2.double_conv.2.bias
 (256)" fillcolor=lightblue]
	129890226786928 -> 129890242004400
	129890242004400 [label=AccumulateGrad]
	129890242004544 -> 129890242004592
	129890226787968 [label="encoder_layers.2.double_conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	129890226787968 -> 129890242004544
	129890242004544 [label=AccumulateGrad]
	129890242004688 -> 129890242004592
	129890226788128 [label="encoder_layers.2.double_conv.3.bias
 (256)" fillcolor=lightblue]
	129890226788128 -> 129890242004688
	129890242004688 [label=AccumulateGrad]
	129890242005072 -> 129890242006992
	129890226788048 [label="encoder_layers.2.double_conv.5.weight
 (256)" fillcolor=lightblue]
	129890226788048 -> 129890242005072
	129890242005072 [label=AccumulateGrad]
	129890242005024 -> 129890242006992
	129890226788368 [label="encoder_layers.2.double_conv.5.bias
 (256)" fillcolor=lightblue]
	129890226788368 -> 129890242005024
	129890242005024 [label=AccumulateGrad]
	129890242005456 -> 129890242005504
	129890226789008 [label="bottleneck.double_conv.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	129890226789008 -> 129890242005456
	129890242005456 [label=AccumulateGrad]
	129890242005600 -> 129890242005504
	129890226789168 [label="bottleneck.double_conv.0.bias
 (512)" fillcolor=lightblue]
	129890226789168 -> 129890242005600
	129890242005600 [label=AccumulateGrad]
	129890242005744 -> 129890242005936
	129890226789248 [label="bottleneck.double_conv.2.weight
 (512)" fillcolor=lightblue]
	129890226789248 -> 129890242005744
	129890242005744 [label=AccumulateGrad]
	129890242005792 -> 129890242005936
	129890226789328 [label="bottleneck.double_conv.2.bias
 (512)" fillcolor=lightblue]
	129890226789328 -> 129890242005792
	129890242005792 [label=AccumulateGrad]
	129890242005984 -> 129890242006032
	129890226790048 [label="bottleneck.double_conv.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	129890226790048 -> 129890242005984
	129890242005984 [label=AccumulateGrad]
	129890242006128 -> 129890242006032
	129890226790128 [label="bottleneck.double_conv.3.bias
 (512)" fillcolor=lightblue]
	129890226790128 -> 129890242006128
	129890242006128 [label=AccumulateGrad]
	129890242006272 -> 129890242006416
	129890226790368 [label="bottleneck.double_conv.5.weight
 (512)" fillcolor=lightblue]
	129890226790368 -> 129890242006272
	129890242006272 [label=AccumulateGrad]
	129890242006320 -> 129890242006416
	129890226790448 [label="bottleneck.double_conv.5.bias
 (512)" fillcolor=lightblue]
	129890226790448 -> 129890242006320
	129890242006320 [label=AccumulateGrad]
	129890242006608 -> 129890242006896
	129890226791648 [label="up_layers.0.weight
 (512, 256, 2, 2)" fillcolor=lightblue]
	129890226791648 -> 129890242006608
	129890242006608 [label=AccumulateGrad]
	129890242006656 -> 129890242006896
	129890226791728 [label="up_layers.0.bias
 (256)" fillcolor=lightblue]
	129890226791728 -> 129890242006656
	129890242006656 [label=AccumulateGrad]
	129890242006992 -> 129890242009824
	129890242010736 -> 129890242010784
	129890226792048 [label="up_convs.0.double_conv.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	129890226792048 -> 129890242010736
	129890242010736 [label=AccumulateGrad]
	129890242011168 -> 129890242010784
	129890226792128 [label="up_convs.0.double_conv.0.bias
 (256)" fillcolor=lightblue]
	129890226792128 -> 129890242011168
	129890242011168 [label=AccumulateGrad]
	129890242012512 -> 129890583577456
	129890226792208 [label="up_convs.0.double_conv.2.weight
 (256)" fillcolor=lightblue]
	129890226792208 -> 129890242012512
	129890242012512 [label=AccumulateGrad]
	129890242018272 -> 129890583577456
	129890226793168 [label="up_convs.0.double_conv.2.bias
 (256)" fillcolor=lightblue]
	129890226793168 -> 129890242018272
	129890242018272 [label=AccumulateGrad]
	129890246989888 -> 129890274247008
	129890226790528 [label="up_convs.0.double_conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	129890226790528 -> 129890246989888
	129890246989888 [label=AccumulateGrad]
	129890246999728 -> 129890274247008
	129890226791088 [label="up_convs.0.double_conv.3.bias
 (256)" fillcolor=lightblue]
	129890226791088 -> 129890246999728
	129890246999728 [label=AccumulateGrad]
	129890232174096 -> 129890560150592
	129890226791568 [label="up_convs.0.double_conv.5.weight
 (256)" fillcolor=lightblue]
	129890226791568 -> 129890232174096
	129890232174096 [label=AccumulateGrad]
	129890232177504 -> 129890560150592
	129890226792288 [label="up_convs.0.double_conv.5.bias
 (256)" fillcolor=lightblue]
	129890226792288 -> 129890232177504
	129890232177504 [label=AccumulateGrad]
	129890560157648 -> 129890119878400
	129890226794208 [label="up_layers.1.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	129890226794208 -> 129890560157648
	129890560157648 [label=AccumulateGrad]
	129890560159280 -> 129890119878400
	129890226794368 [label="up_layers.1.bias
 (128)" fillcolor=lightblue]
	129890226794368 -> 129890560159280
	129890560159280 [label=AccumulateGrad]
	129890119881664 -> 129890246297680
	129890246297872 -> 129890246297920
	129890226794688 [label="up_convs.1.double_conv.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	129890226794688 -> 129890246297872
	129890246297872 [label=AccumulateGrad]
	129890246300896 -> 129890246297920
	129890226794768 [label="up_convs.1.double_conv.0.bias
 (128)" fillcolor=lightblue]
	129890226794768 -> 129890246300896
	129890246300896 [label=AccumulateGrad]
	129890241513936 -> 129890559670160
	129890226797968 [label="up_convs.1.double_conv.2.weight
 (128)" fillcolor=lightblue]
	129890226797968 -> 129890241513936
	129890241513936 [label=AccumulateGrad]
	129890246301184 -> 129890559670160
	129890226798048 [label="up_convs.1.double_conv.2.bias
 (128)" fillcolor=lightblue]
	129890226798048 -> 129890246301184
	129890246301184 [label=AccumulateGrad]
	129890245397712 -> 129890245410000
	129890226797088 [label="up_convs.1.double_conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	129890226797088 -> 129890245397712
	129890245397712 [label=AccumulateGrad]
	129890245409760 -> 129890245410000
	129890226797328 [label="up_convs.1.double_conv.3.bias
 (128)" fillcolor=lightblue]
	129890226797328 -> 129890245409760
	129890245409760 [label=AccumulateGrad]
	129890245409616 -> 129890245408800
	129890226797408 [label="up_convs.1.double_conv.5.weight
 (128)" fillcolor=lightblue]
	129890226797408 -> 129890245409616
	129890245409616 [label=AccumulateGrad]
	129890245407936 -> 129890245408800
	129890226797248 [label="up_convs.1.double_conv.5.bias
 (128)" fillcolor=lightblue]
	129890226797248 -> 129890245407936
	129890245407936 [label=AccumulateGrad]
	129890245408656 -> 129890245407552
	129890226797728 [label="up_layers.2.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	129890226797728 -> 129890245408656
	129890245408656 [label=AccumulateGrad]
	129890245408608 -> 129890245407552
	129890226797888 [label="up_layers.2.bias
 (64)" fillcolor=lightblue]
	129890226797888 -> 129890245408608
	129890245408608 [label=AccumulateGrad]
	129890245405680 -> 129890245406976
	129890245404768 -> 129890245406736
	129890226796688 [label="up_convs.2.double_conv.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	129890226796688 -> 129890245404768
	129890245404768 [label=AccumulateGrad]
	129890245406304 -> 129890245406736
	129890226796768 [label="up_convs.2.double_conv.0.bias
 (64)" fillcolor=lightblue]
	129890226796768 -> 129890245406304
	129890245406304 [label=AccumulateGrad]
	129890245403904 -> 129890245403328
	129890226796928 [label="up_convs.2.double_conv.2.weight
 (64)" fillcolor=lightblue]
	129890226796928 -> 129890245403904
	129890245403904 [label=AccumulateGrad]
	129890245401552 -> 129890245403328
	129890226796208 [label="up_convs.2.double_conv.2.bias
 (64)" fillcolor=lightblue]
	129890226796208 -> 129890245401552
	129890245401552 [label=AccumulateGrad]
	129890245403280 -> 129890232122624
	129890226796448 [label="up_convs.2.double_conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	129890226796448 -> 129890245403280
	129890245403280 [label=AccumulateGrad]
	129890245402656 -> 129890232122624
	129890226791168 [label="up_convs.2.double_conv.3.bias
 (64)" fillcolor=lightblue]
	129890226791168 -> 129890245402656
	129890245402656 [label=AccumulateGrad]
	129890245399968 -> 129890245395696
	129890226795968 [label="up_convs.2.double_conv.5.weight
 (64)" fillcolor=lightblue]
	129890226795968 -> 129890245399968
	129890245399968 [label=AccumulateGrad]
	129890245399920 -> 129890245395696
	129890226796048 [label="up_convs.2.double_conv.5.bias
 (64)" fillcolor=lightblue]
	129890226796048 -> 129890245399920
	129890245399920 [label=AccumulateGrad]
	129890245399344 -> 129890245395456
	129890226795728 [label="final_conv.weight
 (3, 64, 1, 1)" fillcolor=lightblue]
	129890226795728 -> 129890245399344
	129890245399344 [label=AccumulateGrad]
	129890245399776 -> 129890245395456
	129890226782688 [label="final_conv.bias
 (3)" fillcolor=lightblue]
	129890226782688 -> 129890245399776
	129890245399776 [label=AccumulateGrad]
	129890245395456 -> 129890226784608
}
